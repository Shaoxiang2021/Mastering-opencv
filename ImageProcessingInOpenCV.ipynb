{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19f61a73",
   "metadata": {},
   "source": [
    "## Image Processing In OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6ffdac",
   "metadata": {},
   "source": [
    "### Splitting and merging channels in OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a35b2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2032334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "image = cv2.imread(\"./image/logo.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e94a493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to show the image\n",
    "def show_image(frameName, image):\n",
    "    cv2.imshow(frameName, image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95f4860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting channels\n",
    "(b, g, r) = cv2.split(image)\n",
    "\n",
    "# merge them back\n",
    "image_copy = cv2.merge((b, g, r))\n",
    "\n",
    "# splitting channels using numpy vector\n",
    "b = image[:, :, 0]\n",
    "\n",
    "# set blue channel to zero\n",
    "image_without_blue = image.copy()\n",
    "image_without_blue[:, :, 0] = 0\n",
    "\n",
    "# show the image without blue channel\n",
    "show_image(\"image without blue channel\", image_without_blue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9e0dc0",
   "metadata": {},
   "source": [
    "### Scaling an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd2c6492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize image with integer factor\n",
    "(height, width, channelSize) = image.shape\n",
    "# (width, height) = image.shape[:2]\n",
    "\n",
    "resize_image = cv2.resize(image, (width*2, height*2), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "show_image(\"resize image\", resize_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4ed4f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# schrink image\n",
    "dst_image = cv2.resize(image, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "show_image(\"schrink image\", dst_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb59297",
   "metadata": {},
   "source": [
    "If you want to enlarge the image, the best approach is to use the cv2.INTER_CUBIC interpolation method (a time-consuming interpolation method) or cv2.INTER_LINEAR. \n",
    "\n",
    "If you want to shrink the image, the general approach is to use cv2.INTER_LINEAR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfadff0",
   "metadata": {},
   "source": [
    "### Translating an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5ff979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create M transformation matrix\n",
    "M = np.float32([[1, 0, 200], [0, 1, 30]])\n",
    "\n",
    "# affine transformation using M matrix\n",
    "dst_image = cv2.warpAffine(image, M, (width, height)) \n",
    "# width, height are the size of the creating image\n",
    "\n",
    "# show translated image\n",
    "show_image(\"translated image\", dst_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dbc8fc",
   "metadata": {},
   "source": [
    "### Rotating an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bab9c4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create M transformation matrix\n",
    "M = cv2.getRotationMatrix2D((width/2, height/2), 180, 1)\n",
    "# the first argument is rotaion center, the second is rotation angle, the third is scale factor\n",
    "\n",
    "# affine transformation using M matrix\n",
    "dst_image = cv2.warpAffine(image, M, (width, height))\n",
    "\n",
    "# compare with original image\n",
    "imageShow = np.concatenate((image, dst_image), axis=1)\n",
    "\n",
    "# show image\n",
    "show_image(\"compare images\", imageShow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6e00155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# three points paar determine the transformation matrix\n",
    "point_origin = np.float32([[135, 45], [385, 45], [135, 230]])\n",
    "point_transformated = np.float32([[135, 45], [385, 45], [150, 230]])\n",
    "M = cv2.getAffineTransform(point_origin, point_transformated)\n",
    "dst_image = cv2.warpAffine(image, M, (width, height))\n",
    "\n",
    "# show image\n",
    "show_image(\"translated image\", dst_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47fe978",
   "metadata": {},
   "source": [
    "### Perspective transformation of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "111c9d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flour points paar determine the perspective transformation matrix\n",
    "point_origin = np.float32([[450, 65], [517, 65], [431, 164], [552, 164]])\n",
    "point_transformated = np.float32([[0, 0], [300, 0], [0, 300], [300, 300]])\n",
    "M = cv2.getPerspectiveTransform(point_origin, point_transformated)\n",
    "dst_image = cv2.warpPerspective(image, M, (width, height))\n",
    "\n",
    "# show image\n",
    "show_image(\"translated image\", dst_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae27721b",
   "metadata": {},
   "source": [
    "### Image filtering - Applying arbitrary kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b60bf844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create kernel matrix\n",
    "kernel_averaging_5_5 = np.ones((5, 5), np.float32) / 25\n",
    "\n",
    "# kernel handle in image\n",
    "smooth_image_f2D = cv2.filter2D(image, -1, kernel_averaging_5_5)\n",
    "\n",
    "# show image\n",
    "show_image(\"smooth image\", smooth_image_f2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63966d25",
   "metadata": {},
   "source": [
    "### Smoothing images - Averaging filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c022dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_image_b = cv2.blur(image, (10, 10))\n",
    "smooth_image_bfi = cv2.boxFilter(image, -1, (10, 10), normalize=True)\n",
    "\n",
    "smooth_image_f2D = np.concatenate((smooth_image_b, smooth_image_bfi), axis=1)\n",
    "                                 \n",
    "# show image\n",
    "show_image(\"smooth image (using blur and boxFilter)\", smooth_image_f2D)                       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073ac236",
   "metadata": {},
   "source": [
    "### Gaussian filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ae87b10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_image_gb = cv2.GaussianBlur(image, (9, 9), 0)\n",
    "# the third argument is sigmaX and sigmaY, if equal to zero will be choose automatically\n",
    "\n",
    "smooth_image_f2D = np.concatenate((image, smooth_image_gb), axis=1)\n",
    "\n",
    "# show image\n",
    "show_image(\"smooth image (using gaussfilter)\", smooth_image_f2D)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fdd389",
   "metadata": {},
   "source": [
    "### Median filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "11f5ecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_image_mb = cv2.medianBlur(image, 9)\n",
    "\n",
    "smooth_image_f2D = np.concatenate((image, smooth_image_mb), axis=1)\n",
    "\n",
    "# show image\n",
    "show_image(\"smooth image (using gaussfilter)\", smooth_image_f2D) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfec0ebf",
   "metadata": {},
   "source": [
    "### Bilateral filtering\n",
    "\n",
    "This function can be applied to reduce noise while keeping the edges sharp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cfa4c10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_image_bf = cv2.bilateralFilter(image, 5, 10, 10)\n",
    "\n",
    "smooth_image_f2D = np.concatenate((image, smooth_image_bf), axis=1)\n",
    "\n",
    "# show image\n",
    "show_image(\"smooth image (using bilateral filtering)\", smooth_image_f2D) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cae120b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"./image/statue_small.jpg\")\n",
    "(height, width) = image.shape[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6750de",
   "metadata": {},
   "source": [
    "### Sharpening images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8f23b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed = cv2.GaussianBlur(image, (9, 9), 10)\n",
    "unsharped = cv2.addWeighted(image, 1.5, smoothed, -0.5, 0)\n",
    "\n",
    "image_sharpen_compare = np.concatenate((image, smoothed, unsharped), axis=1)\n",
    "\n",
    "# show image\n",
    "show_image(\"sharpening images\", image_sharpen_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd91e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
